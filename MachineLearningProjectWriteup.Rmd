---
title: 'Coursera: Machine Learning Course Project'
author: "Cromwell Ellamil"
date: "Friday, October 24, 2014"
output: html_document
---




Overview
-------------------------------------------------------------------------------



A group of enthusiasts took measurements about themselves to find patterns in
the personal activities that they did.  These were measured using accelerometers
on the belt, forearm, and dumbell of 6 participants.  They were asked to perform
barbell lifts correctly and incorrectly in 5 different ways.



The data gathered in the above-mentioned activities, which was also used for
this course project came from Groupware@LES (http://groupware.les.inf.puc-rio.br/).



*Human Activity Recognition*

http://groupware.les.inf.puc-rio.br/har



*Training data*

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv



*Test data*

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv



This course project aims to predict the manner in which one performs a particular
activity, referred to as the "**classe**" variable in the training set.




Setup
-------------------------------------------------------------------------------



The following R libraries were used in this project:

```{r}
library(caret)
library(randomForest)
```



The training and testing data were placed in "*../Data/Training Data*" and
"*..Data/Testing Data*" directories under my R project respectively.

```{r}
trainingData <- "./Data/Training Data/pml-training.csv"
testingData  <- "./Data/Testing Data/pml-testing.csv"
```



We load the training and testing data, like as follows:

```{r}
load.data <- function(file) {
    read.csv(file, row.names = 1)
}

training <- load.data(trainingData)
testing  <- load.data(testingData)
```




Data Cleaning
-------------------------------------------------------------------------------



We clean the data by removing near zero covariates and missing values. For this
course project, we removed data with more than 80% missing values from the 
training data.

```{r}
remove.nearzero.covariates <- function(data) {
    near.zero <- nearZeroVar(data, saveMetrics = TRUE)
    data[, !near.zero$nzv]
}

remove.missing.values <- function(data) {
    missing.values <- sapply(colnames(data), function(col) {
        if (sum(is.na(data[, col]))/nrow(data) > 0.8) {
            return(TRUE)
        }
        else {
            return(FALSE)
        }
    })
    data[, !missing.values]
}

clean.data <- function(data) {
    data <- remove.nearzero.covariates(data)
    remove.missing.values(data)
}

training <- clean.data(training)
```




Training & Cross-Validation
--------------------------------------------------------------------------------



We perform cross-validation by first, splitting the training data further into 
train & test subsets.

```{r}
cross.validation <- function(trainingData) {
    createDataPartition(trainingData$class, p = 0.6, 
                        list = FALSE)
}

trainingIndex  <- cross.validation(training)
training.train <- training[trainingIndex, ]
training.test  <- training[-trainingIndex, ]
```



For this course project, I tried to use **Random Forest** (i.e., **method="rf"**), 
which is the default training method, for model fitting.

(Notice that the method parameter was no longer explicitly specified in the 
**train** function call, since **rf** is already the default method)

I also set the **seed** prior to training to make the results reproducible.

```{r}
fit.model <- function(trainingData) {
    set.seed(123)
    train(classe ~ ., data = trainingData, 
          tuneGrid = data.frame(mtry=3),
          trControl = trainControl(method="oob"))
}

training.train.modelFit <- fit.model(training.train)
```



Let's check the accuracy of this model.

```{r}
training.train.modelFit
```



Notice that the Accuracy is quite high.  Let's proceed with cross-validating the
train & test subsets of the training data.

```{r}
confusionMatrix(predict(training.train.modelFit, newdata = training.test), 
                factor(training.test$classe))
```



The Accuracy is relatively high as well.  So, let's use it in predicting the 
"**classe**" variable for the real testing data, which we haven't touched yet.




Submission of Predictions
--------------------------------------------------------------------------------



The **Predictions** directory was created to store the prediction file outputs. 
We use the modelFit created above to predict the "**classe**" variable in our
testing data.  The prediction file outputs were written as follows:

```{r}
predict.using.data <- function(modelFit, data) {
    as.character(predict(modelFit, newdata = data))
}

write.predictions <- function(x) {
    n <- length(x)
    for (i in 1:n) {
        file <- paste0("./Predictions/problem_id_", i, ".txt")
        write.table(x[i], file = file, 
                    quote = FALSE, row.names = FALSE,
                    col.names = FALSE)
    }
}

predictions <- predict.using.data(training.train.modelFit, 
                                  testing)
write.predictions(predictions)
```




Conclusion
-------------------------------------------------------------------------------

**Random Forest** is an effective method for predicting the manner in which one 
performs a particular activity using accelerometers, such as what were used in
the Human Activity Recognition (HAR) project.